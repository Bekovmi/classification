model_params:
  fp16: false       # general flag
  model: baseline
  encoder_params:
    arch: resnet18
    pretrained: True
    frozen: True
    pooling: GlobalConcatPool2d
  head_params:
    hiddens: [1024]
    emb_size: 64
    n_cls: 2
    activation_fn: ReLU
    norm_fn: BatchNorm1d
    bias: false
    dropout: 0.5

args:
  workers: 4
  expdir: "finetune"
  baselogdir: "./logs/finetune"

stages:

  criterion_params:
      criterion: CrossEntropyLoss

  optimizer_params:
    optimizer: Adam
    lr: 0.001
    weight_decay: 0.0001

  data_params:
    num_workers: 4
    batch_size: 64
    in_csv: "./data/ants_bees/dataset.csv"
    tag2class: "./data/ants_bees/tag2cls.json"
    tag_column: "tag"
    class_column: "class"
    n_folds: 5
    train_folds: [0, 1, 2, 3]
    datapath: "./data/ants_bees/"

  callbacks_params:
    loss:
      callback: EmbeddingsLossCallback
      emb_l2_reg: -1
      input_key: targets
      embeddings_key: embeddings
      logits_key: logits
    optimizer:
      callback: OptimizerCallback
    finder:
      callback: LRFinder
      final_lr: 0.01
      n_steps: 1000
